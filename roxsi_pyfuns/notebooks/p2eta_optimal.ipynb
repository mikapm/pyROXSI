{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pressure - $\\eta$ transforms\n",
    "Find optimal parameters for transforming Asilomar Small-Scale Array pressure measurements to sea-surface elevation $\\eta$. Test both regular linear transfer function and the $\\kappa_\\mathrm{rms}$-based methods of Martins et al. (2021, JPO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import scipy.stats as stats\n",
    "from scipy import signal\n",
    "from scipy.io import loadmat\n",
    "from tqdm.notebook import tqdm\n",
    "import cmocean\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.dates as mdates\n",
    "from cmcrameri import cm\n",
    "from PyPDF2 import PdfFileMerger, PdfFileReader\n",
    "# Interactive plots\n",
    "%matplotlib widget \n",
    "\n",
    "from roxsi_pyfuns import coordinate_transforms as rpct\n",
    "from roxsi_pyfuns import transfer_functions as rptf\n",
    "from roxsi_pyfuns import wave_spectra as rpws\n",
    "\n",
    "# Paths\n",
    "rootdir = r'/media/mikapm/T7 Shield/ROXSI/Asilomar2022/SmallScaleArray/'\n",
    "data_root = os.path.join(rootdir, 'Signatures', 'Level1')\n",
    "bathydir = os.path.join(rootdir, 'Bathy')\n",
    "figdir = os.path.join(data_root, 'img')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test different transfer function parameters for pressure-$\\eta$ reconstruction and compare against acoustic surface track (AST) signal from Nortek Signature 1000 ADCPs around the SSA rock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:  2022-06-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "mids = ['C1', 'C3', 'C6'] # Mooring IDs\n",
    "sers = ['103088', '103094', '103110'] # Serial numbers\n",
    "\n",
    "# Define segment timestamps\n",
    "t0 = pd.Timestamp('2022-06-28 00:00') # start date\n",
    "t1 = pd.Timestamp('2022-06-29 00:00') # start date\n",
    "nm = 20 # time series length (number of minutes)\n",
    "tfreq = '{}T'.format(nm) # Time step between timestamps in date range\n",
    "date_range = pd.date_range(t0, t1, freq='1D')\n",
    "\n",
    "# K_rms transformation parameters\n",
    "tail_method = 'constant'\n",
    "fix_ends = False\n",
    "fmax = 1.0\n",
    "\n",
    "for date in date_range:\n",
    "    print('Date: ', str(date))\n",
    "    # Split date into nm-minute segments\n",
    "    rec_range = pd.date_range(date, date+pd.Timedelta(days=1), freq=tfreq)\n",
    "    # Iterate over nm-minute segments and transform pressure -> eta and plot\n",
    "    for cnt, t0s in enumerate(rec_range):\n",
    "        t1s = t0s + pd.Timedelta(minutes=nm)\n",
    "\n",
    "        # Initialize figure\n",
    "        fig, axes = plt.subplots(figsize=(9,7), nrows=3, ncols=2, sharex='col', sharey='col',\n",
    "                                gridspec_kw={'width_ratios': [3, 1]}, constrained_layout=True)\n",
    "        # Iterate over mooring IDs and serial numbers\n",
    "        for i, (mid, ser) in enumerate(zip(mids, sers)):\n",
    "            # print('Mooring ID: ', mid)\n",
    "            # Signature velocity netcdf directory\n",
    "            veldir = os.path.join(data_root, '{}'.format(ser)) \n",
    "            # List netcdf files in veldir\n",
    "            fns_v = sorted(glob.glob(os.path.join(veldir, 'Asilomar_*.nc')))\n",
    "            if str((t0s - pd.Timedelta(minutes=nm/2)).date()) != str(t0s.date()):\n",
    "                # Combine current and previous dates\n",
    "                t00s = (t0s - pd.Timedelta(minutes=nm/2)).date() # Previous date\n",
    "                # Read Signature velocity dataset for current date\n",
    "                datestr = '{}{:02d}{:02d}'.format(t0s.year, t0s.month, t0s.day)\n",
    "                fn_sig = [f for f in fns_v if datestr in f]\n",
    "                # Read current date's dataset\n",
    "                dsc = xr.decode_cf(xr.open_dataset(fn_sig[0], decode_coords='all'))\n",
    "                # Read Signature velocity dataset for previous date\n",
    "                datestr0 = '{}{:02d}{:02d}'.format(t00s.year, t00s.month, t00s.day)\n",
    "                fn_sig0 = [f for f in fns_v if datestr0 in f]\n",
    "                # Read previous date's dataset\n",
    "                ds0 = xr.decode_cf(xr.open_dataset(fn_sig0[0], decode_coords='all'))\n",
    "                # Concatenate current+previous datasets\n",
    "                ds = xr.concat([ds0, dsc], dim='time')\n",
    "            elif str((t1s + pd.Timedelta(minutes=nm/2)).date()) != str(t1s.date()):\n",
    "                # Combine current and following dates\n",
    "                t11s = (t1s + pd.Timedelta(minutes=nm/2)).date() # Following date\n",
    "                # Read Signature velocity dataset for current date\n",
    "                datestr = '{}{:02d}{:02d}'.format(t0s.year, t0s.month, t0s.day)\n",
    "                fn_sig = [f for f in fns_v if datestr in f]\n",
    "                # Read current date's dataset\n",
    "                dsc = xr.decode_cf(xr.open_dataset(fn_sig[0], decode_coords='all'))\n",
    "                # Read Signature velocity dataset for following date\n",
    "                datestr1 = '{}{:02d}{:02d}'.format(t11s.year, t11s.month, t11s.day)\n",
    "                fn_sig1 = [f for f in fns_v if datestr1 in f]\n",
    "                # Read following date's dataset\n",
    "                ds1 = xr.decode_cf(xr.open_dataset(fn_sig1[0], decode_coords='all'))\n",
    "                # Concatenate current+following datasets\n",
    "                ds = xr.concat([dsc, ds1], dim='time')\n",
    "            else:\n",
    "                # Read Signature velocity dataset for current date\n",
    "                datestr = '{}{:02d}{:02d}'.format(t0s.year, t0s.month, t0s.day)\n",
    "                fn_sig = [f for f in fns_v if datestr in f]\n",
    "                # In some cases, 30.6 and 1.7 dates are combined into one netcdf file\n",
    "                sk = np.logical_and(np.logical_or(mid=='C3', mid=='C6'), \n",
    "                                    str(t0s.date())=='2022-06-30')\n",
    "                if not sk:\n",
    "                    ds = xr.decode_cf(xr.open_dataset(fn_sig[0], decode_coords='all'))\n",
    "                else:\n",
    "                    fn_sig = [f for f in fns_v if '20220701' in f]\n",
    "                    ds = xr.decode_cf(xr.open_dataset(fn_sig[0], decode_coords='all'))\n",
    "            # Take requested segment from dataset\n",
    "            seg = ds.sel(time=slice(t0s, t1s)).copy() # Segment slice\n",
    "            # Directional wave spectra\n",
    "            # Use AST and pressure for spectra\n",
    "            eta_ast = seg.ASTd_eta.values # AST\n",
    "            eta_hyd = seg.eta_hyd.values # hydrostatic surface\n",
    "            z_hyd = seg.z_hyd.values # hydrostatic pressure head\n",
    "            time_index = seg.time.values # Time index for dataframe\n",
    "            # Save eta products to dataframe\n",
    "            dfe = pd.DataFrame(data={'eta_hyd': eta_hyd, 'eta_ast': eta_ast},\n",
    "                            index=time_index)\n",
    "            # Estimate AST and hydrostatic spectra\n",
    "            dss = rpws.spec_uvz(z=eta_ast, fs=4, wsec=256, fmerge=3)\n",
    "            dssh = rpws.spec_uvz(z=eta_hyd, fs=4, wsec=256, fmerge=3)\n",
    "            dss['Ehh'] = (['freq'], dssh.Ezz.values)\n",
    "            # Reconstruct eta from pressure for different cut-off frequencies\n",
    "            fcs = [0.25, 0.3, 0.35] # cut-off freqs (Hz)\n",
    "            lss = ['-', '--', ':'] # Linestyles for fc values\n",
    "            for fi,fc in enumerate(fcs):\n",
    "                # Initialize TRF object\n",
    "                trf = rptf.TRF(fs=4, zp=0.3)\n",
    "                # Regular linear reconstruction (returns depth)\n",
    "                z_lin = trf.p2z_lin(z_hyd, fmax=fc)\n",
    "                depth = np.mean(z_lin)\n",
    "                eta_lin = z_lin - depth\n",
    "                # Compute bispectrum and use it to get K_rms\n",
    "                dsb = rpws.bispectrum(eta_hyd, fs=4, h0=depth, return_krms=True)\n",
    "                krms = dsb.k_rms.values\n",
    "                f_krms = dsb.freq1.values\n",
    "                # (Non)linear K_rms reconstructions\n",
    "                eta_lin_krms, eta_nl_krms = trf.p2eta_krms(eta_hyd, h0=depth, fc=fc, \n",
    "                    fcmax_allowed=fc, f_krms=f_krms, krms=krms, return_nl=True, fmax=fmax, \n",
    "                    fp=(1 / dss.Tp_Y95.item()), fix_ends=fix_ends, tail_method=tail_method)\n",
    "                # Fix end points with overlapping reconstructions\n",
    "                t0ob = t0s - pd.Timedelta(minutes=(nm/2)) # half period before t0\n",
    "                t1ob = t0s + pd.Timedelta(minutes=(nm/2)) # half period before t1\n",
    "                # Get hydrostatic signal \n",
    "                seg0 = ds.sel(time=slice(t0ob, t1ob)).copy() # Overlap segment slice\n",
    "                times0 = seg0.time.values\n",
    "                z_hyd0 = seg0.z_hyd.values\n",
    "                eta_hyd0 = z_hyd0 - np.mean(z_hyd0)\n",
    "                # Reconstruct linear\n",
    "                z_lin0 = trf.p2z_lin(z_hyd0, fmax=fc)\n",
    "                eta_lin0 = z_lin0 - depth\n",
    "                # Reconstruct (non)linear K_rms\n",
    "                eta_lin_krms0, eta_nl_krms0 = trf.p2eta_krms(eta_hyd0, h0=depth, fc=fc, \n",
    "                    fcmax_allowed=fc, f_krms=f_krms, krms=krms, return_nl=True, fmax=fmax, \n",
    "                    fp=(1 / dss.Tp_Y95.item()), fix_ends=fix_ends, tail_method=tail_method)\n",
    "                # Also get half period after\n",
    "                t0oa = t1s - pd.Timedelta(minutes=(nm/2)) # half period before t0\n",
    "                t1oa = t1s + pd.Timedelta(minutes=(nm/2)) # half period before t1\n",
    "                # Get hydrostatic signal \n",
    "                seg1 = ds.sel(time=slice(t0oa, t1oa)).copy() # Overlap segment slice\n",
    "                times1 = seg1.time.values\n",
    "                z_hyd1 = seg1.z_hyd.values\n",
    "                eta_hyd1 = z_hyd1 - np.mean(z_hyd1)\n",
    "                # Reconstruct linear\n",
    "                z_lin1 = trf.p2z_lin(z_hyd1, fmax=fc)\n",
    "                eta_lin1 = z_lin1 - depth\n",
    "                # Reconstruct (non)linear K_rms\n",
    "                eta_lin_krms1, eta_nl_krms1 = trf.p2eta_krms(eta_hyd1, h0=depth, fc=fc, \n",
    "                    fcmax_allowed=fc, f_krms=f_krms, krms=krms, return_nl=True, fmax=fmax, \n",
    "                    fp=(1 / dss.Tp_Y95.item()), fix_ends=fix_ends, tail_method=tail_method)\n",
    "                # Make dataframes and merge end points\n",
    "                dfm0 = pd.DataFrame(data={'eta_lin': eta_lin0, \n",
    "                                        'eta_lin_krms':eta_lin_krms0, \n",
    "                                        'eta_nl_krms':eta_nl_krms0, \n",
    "                                        },\n",
    "                                    index=times0)\n",
    "                dfm0.index = dfm0.index.rename('time')\n",
    "                dfm = pd.DataFrame(data={'eta_lin': eta_lin, \n",
    "                                        'eta_lin_krms':eta_lin_krms, \n",
    "                                        'eta_nl_krms':eta_nl_krms, \n",
    "                                        },\n",
    "                                    index=time_index)\n",
    "                dfm.index = dfm.index.rename('time')\n",
    "                dfm1 = pd.DataFrame(data={'eta_lin': eta_lin1, \n",
    "                                        'eta_lin_krms':eta_lin_krms1, \n",
    "                                        'eta_nl_krms':eta_nl_krms1, \n",
    "                                        },\n",
    "                                    index=times1)\n",
    "                dfm1.index = dfm1.index.rename('time')\n",
    "                # Merge left and right dataframes with original (middle)\n",
    "                dfl = dfm.join(dfm0, on='time', how='left', lsuffix='_o', rsuffix='_l')\n",
    "                dfr = dfm.join(dfm1, on='time', how='left', lsuffix='_o', rsuffix='_r')\n",
    "                # Use first 100 samples from left dataframe to fix start edge effects\n",
    "                eta_lin_m = np.concatenate((dfl['eta_lin_l'].iloc[:100], \n",
    "                                            dfl['eta_lin_o'].iloc[100:]))\n",
    "                eta_lin_krms_m = np.concatenate((dfl['eta_lin_krms_l'].iloc[:100], \n",
    "                                                dfl['eta_lin_krms_o'].iloc[100:]))\n",
    "                eta_nl_krms_m = np.concatenate((dfl['eta_nl_krms_l'].iloc[:100], \n",
    "                                                dfl['eta_nl_krms_o'].iloc[100:]))\n",
    "                # Use last 100 samples from right dataframe to fix end edge effects\n",
    "                eta_lin_m = np.concatenate((eta_lin_m[:-100], dfr['eta_lin_r'].iloc[-100:]))\n",
    "                eta_lin_krms_m = np.concatenate((eta_lin_krms_m[:-100], \n",
    "                                                dfr['eta_lin_krms_r'].iloc[-100:]))\n",
    "                eta_nl_krms_m = np.concatenate((eta_nl_krms_m[:-100], \n",
    "                                                dfr['eta_nl_krms_r'].iloc[-100:]))\n",
    "                # Save reconstructions to dataframe\n",
    "                dfe['etal-{}'.format(fc)] = eta_lin_m\n",
    "                dfe['etalk-{}'.format(fc)] = eta_lin_krms_m\n",
    "                dfe['etank-{}'.format(fc)] = eta_nl_krms_m\n",
    "                # Estimate spectra\n",
    "                dssl = rpws.spec_uvz(eta_lin_m, fs=4)\n",
    "                dss['etal-{}'.format(fc)] = (['freq'], dssl.Ezz.values)\n",
    "                dsslk = rpws.spec_uvz(eta_lin_krms_m, fs=4)\n",
    "                dss['etalk-{}'.format(fc)] = (['freq'], dsslk.Ezz.values)\n",
    "                dssnk = rpws.spec_uvz(eta_nl_krms_m, fs=4)\n",
    "                dss['etank-{}'.format(fc)] = (['freq'], dssnk.Ezz.values)\n",
    "                # Plot reconstructed eta and spectra\n",
    "                dfe['etal-{}'.format(fc)].plot(ax=axes[i,0], color='#2E86AB', linestyle=lss[fi],\n",
    "                                            label='_', linewidth=0.8)\n",
    "                dfe['etalk-{}'.format(fc)].plot(ax=axes[i,0], color='#A23B72', linestyle=lss[fi],\n",
    "                                                label='_', linewidth=0.8)\n",
    "                dfe['etank-{}'.format(fc)].plot(ax=axes[i,0], color='#F18F01', linestyle=lss[fi],\n",
    "                                                label='_', linewidth=0.8)\n",
    "                # Spectra\n",
    "                dss['etal-{}'.format(fc)].plot(ax=axes[i,1], color='#2E86AB', linestyle=lss[fi],\n",
    "                    label=r'$\\eta_\\mathrm{l}$, $f_\\mathrm{c}$'+'={}'.format(fc),\n",
    "                    linewidth=0.8,\n",
    "                    )\n",
    "                dss['etalk-{}'.format(fc)].plot(ax=axes[i,1], color='#A23B72', linestyle=lss[fi],\n",
    "                    label=r'$\\eta_\\mathrm{l, krms}$, $f_\\mathrm{c}$'+'={}'.format(fc),\n",
    "                    linewidth=0.8,\n",
    "                    )\n",
    "                dss['etank-{}'.format(fc)].plot(ax=axes[i,1], color='#F18F01', linestyle=lss[fi],\n",
    "                    label=r'$\\eta_\\mathrm{nl, krms}$, $f_\\mathrm{c}$'+'={}'.format(fc),\n",
    "                    linewidth=0.8,\n",
    "                    )\n",
    "            # Also plot AST eta and spectrum\n",
    "            dfe['eta_ast'].plot(ax=axes[i,0], color='k', label=r'$\\eta_\\mathrm{AST}$')\n",
    "            dss.Ezz.plot(ax=axes[i,1], color='k')\n",
    "            # Annotate mooring ID and depth\n",
    "            axes[i,0].annotate('{} depth={:.2f}m'.format(mid, depth), xy=(0.01, 0.9), \n",
    "                            xycoords='axes fraction', fontsize=10)\n",
    "            # Legend on top row\n",
    "            axes[0,1].legend(ncols=1, fontsize=7, loc='center left', bbox_to_anchor=(1,0.5))\n",
    "            # AST legend in 0,0\n",
    "            axes[0,0].legend(ncols=1, fontsize=7, loc='upper right')\n",
    "            # Set spectrum plot axes to semilogy scale and zoom in to mid frequencies\n",
    "            axes[i,1].set_yscale('log')\n",
    "            axes[i,1].set_xlim([0.1, 0.5])\n",
    "            axes[i,1].set_xticks([0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "            axes[i,1].set_ylim([0.01, dss.Ezz.max() + 0.5])\n",
    "        axes[0,0].set_title('{}-{}'.format(str(t0s), str(t1s.time())))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        # Figure filename\n",
    "        ds = ''.join(str(date.date()).split('-')) # Datestr in format yyyymmdd\n",
    "        fn_fig = os.path.join(figdir, 'p2eta_comp_{}_{:03d}.pdf'.format(ds, cnt))\n",
    "        if not os.path.isfile(fn_fig):\n",
    "            plt.savefig(fn_fig, bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    raise ValueError('Stop')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20220628'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('roxsi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e715d662fe8e22131a1a27297cc1d49e0381d8e0a8bc028f15597f0e40cad389"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
